
---
wp_id: 896
wp_post_status: "publish" 
title: "AEA 2013 Re-Cap, Part 1"
date: 2013-11-21T17:20:56+05:00
date_modified: 2014-02-27T15:46:10+05:00
date_published: 2013-11-21T17:20:56+05:00
primary_category: "Crc Team"
categories: ['Crc Team'] 
tags: ['american evaluation association', 'team building', 'professional development']
seo_title: "aea 2013 re-cap, part 1"
seo_meta_description: ""
summary: ""
featured_image_url: "no image"
slug: "aea-2013-re-cap-part-1"
url: "https://www.inciter.io/aea-2013-re-cap-part-1/"
authors: CRC
---

#Content

<span style="color: #808080;">_compiled by Jill Scheibler_</span>
__<span style="color: #000000;">CRC was well represented at the</span> <a href="http://www.eval.org/p/cm/ld/fid=21" target="_blank">2013 American Evaluation Association conference</a>, held close to home for us in Washington, DC!&nbsp;__We learned a lot from this year’s sessions and had a great time connecting with old and new friends… But we didn’t just party there! (Although we did do&nbsp;_just a bit_&nbsp;of that with our fellow East Coast evalutors… see the evidence at the end of this post.)
<span style="color: #000000;">Most of our staff attended AEA 2013, and each has something to share about what she learned there. Together we have so much to share, actually, that we’ll be splitting our conference post-mortem into two parts.&nbsp;___Stay tuned for part 2, coming next week!___</span>
&nbsp;
__Dana Ansari, Research Assistant,&nbsp;__attended a plenary presented by John Easton, entitled,__&nbsp;“__The Practice of Educational Evaluation Today: A Federal Perspective.” Her key take-aways from the presentation were:____
1. Working partnerships between evaluators and stakeholders are important for making research both pertinent and functional.____
2. Formative evaluations are useful in gathering feedback and identifying a program’s strengths and weaknesses, which can then be used to improve future implementation efforts. Randomized controlled trials are useful in making casual linkages; however, they may sometimes lack the ability to capture the reasons behind the&nbsp;_why_&nbsp;and the&nbsp;_what&nbsp;_of a given intervention makes it so effective.
3. Drawing from various research and evaluation approaches can help evaluators choose the most effective method for program improvement and success
__Leslie Gabay-Swanston, Research Analyst,&nbsp;__distilled a couple of take-aways from different sessions that she attended:
_Number one_, was that a distinction should be drawn between assessment and evaluation:
Assessment =&nbsp;_What_&nbsp;do we know?
Evaluation =&nbsp;_How&nbsp;_do we know?
Evaluation =&nbsp;_How&nbsp;_do we know?
Within a circular process, assessment and evaluation use the same elements, just in a different way.
_Number two_, was a set of useful distinctions between evaluation types:
Collaborative Evaluation = &nbsp;Evaluators are in charge; there is ongoing engagement between evaluators and stakeholders.
Participatory Evaluation = Control is jointly shared; participants are very involved in the evaluation process.
Empowerment Evaluation = Participants are in control of the evaluation; the evaluator is a “critical friend”.Related to empowerment evaluation, an ongoing challenge for evaluators is how to help participants to be comfortable and confident enough to carry the evaluation forward.
<div style="text-align: center;"><dl id="attachment_247"><dt></dt><dd>
[caption id="attachment_1193" align="aligncenter" width="327"] Michael Quinn Patton (aka, Sheila's "best friend, MQP") presented this year, as he often does.[/caption]
<span style="line-height: 1.5em;">&nbsp;</span></dd></dl></div>
__Mandi Singleton, Research Assistant__, attended a workshop entitled “21<sup>st</sup>&nbsp;Century Strategies for Conducting Excellent Interviews.” &nbsp;It provided pointers for conducting long interviews, presented the concepts of “companioning” and motivational interviewing (MI). Mandi learned that:
<ol start="1">
<li>“Companioning” involves practicing effective listening skills that aim to increase the quality of responses. This process focuses on what virtues you – as the interviewer— bring to the table (e.g., being aware of your own biases, respecting the interviewee, maintaining focus, practicing open-mindedness, non-verbal communication/body language, interest and engagement). The interviewer should exude: 1) compassion – to actively engage the interviewee, and 2) detachment – understanding the interviewee while not taking on their emotions.</li>
<li>Motivational interviewing is powerful in combating cases of resistance (i.e., a lack of agreement on goals between interviewer and interviewee) in participants. In MI, interviewers should focus on the dimensions of:</li>
</ol>
*   Collaboration&nbsp;rather than confrontation (e.g., engage as partners; don’t confront as to how they should change)
*   Evocation&nbsp;rather than education (e.g., evoke from participant, don’t push them to say)
*   Recognizing participants’&nbsp;autonomy&nbsp;rather than expressing your authority, making them the agents of change and experts of their own situations
Mandi also picked up a few pointers on how to increase participant engagement and reduce dropout when conducting long-interviews:
<ol start="1">
<li>Consolidate</li>
<li>Focus on relationships and building trust with the interviewee</li>
<li>Be clear (on time and content); transparent</li>
<li>Clarify own goals to get richer data (focus on quality vs. quantity)</li>
<li>Avoid leading (leading interview to get the answers you want)</li>
<li>Leave space for open-ended questions</li>
<li>Break-up sessions to reduce interviewee fatigue</li>
<li>Provide incentives</li>
<li>Be sensitive to timing, make it convenient for participant</li>
<li>Create buy-in, explain to participant how it will benefit them</li>
</ol>
&nbsp;
<span style="color: #000000;">__We hope the first part of our AEA 2013 re-cap was informative for you! And now, for our "happy snaps":__</span>
&nbsp;

