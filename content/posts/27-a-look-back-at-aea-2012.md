
---
wp_id: 136
wp_post_status: "publish" 
title: "A Look Back at AEA 2012"
date: 2012-11-26T11:41:31+05:00
date_modified: 2017-05-08T13:39:02+05:00
date_published: 2012-11-26T11:41:31+05:00
primary_category: "Events"
categories: ['Events'] 
tags: ['conferences', 'social media', 'evaluation', 'american evaluation association']
seo_title: "a look back at aea 2012"
seo_meta_description: ""
summary: ""
featured_image_url: "no image"
slug: "a-look-back-at-aea-2012"
url: "https://www.inciter.io/a-look-back-at-aea-2012/"
authors: CRC
---

#Content

It's already the end of November, and we’re entering that time of year when people are inclined to look back and reflect on the events of the previous months. At CRC we are not quite ready to reminisce about all of 2012 just yet, but before November ends we do want to revisit an important event for us that occurred a few weeks ago. At the end of October, some of the CRC staff flew out to Minneapolis to attend the American Evaluation Association conference (and to see our first snowfall of the season!).



If you follow CRC on twitter and/or facebook*, you already know that CRC was busy at this year’s AEA! Leslie and Taj (on behalf of Jenn, too pregnant to fly) presented _Using an Adaptive R__esearch Design in the Evaluation of a Community&nbsp;__Schools Program: &nbsp;Initial Findings&nbsp;__of the Implementation and Evaluation Of Elev8 Baltimore_, and as the leadership of Baltimore Area Evaluators they helped to coordinate a tweetup of East Coast evaluators.

Taj also provided her insights to other evaluators at _Meet the Pros: Intermediate Consulting Skill Building Self-Help Fair_. Sheila was extremely busy with intensive all day workshops, and was social networking like mad on CRC’s behalf. Yet somehow she still had time to meet and pick the brain of AEA President Rodney Hopson.

Collectively, our group had other fortuitous meetings with colleagues and various evaluation celebrities, enjoyed networking with fellow data snobs from the East Coast and beyond, and came away with some valuable lessons learned.The title and theme of the 2012 conference was __Evaluation in Complex Ecologies Relationships, Responsibilities, Relevance__:

<span style="color: #ff9900;">_Evaluation takes place in complex global and local ecologies where we evaluators play important roles in building better organizations and communities and in creating opportunities for a better world. Ecology is about how systems work, engage, intersect, transform, and interrelate. Complex ecologies are comprised of relationships, responsibilities, and relevance within our study of programs, policies, projects, and other areas in which we carry out evaluations._</span>

This theme is extremely relevant to the work that CRC does with our clients-- of diverse types, scale, and needs. Here are a few notable take-aways for three of us:

__Sheila:__

One of the programs that Sheila attended was a day-long Logic Modeling workshop. From this workshop she gleaned that:
1. A little logic modeling goes a long way
2. Logic models make program theory clear, not true

She also picked up some new pointers about data visualization:
1. Strive to make things clear
2. Simplicity enhances clarity
3. Have a single message4. A picture is worth a thousand words: They provide a medium for explaining thought and feeling

&nbsp;
<p style="text-align: left;"><strong>Leslie:</strong></p>
<p style="text-align: left;">Karen Kirkhart, the discussant for Fiona Cram’s plenary (titled, <em>Taking a walk </em><em>&nbsp; on the Wild Side: Some Indigenous Perspective on Valuing Complexity, Sustaining Relationships, Being Accountable for&nbsp;</em><em>Responsibilities and Making&nbsp;</em><em>Things Relevant</em>), provided intriguing parting questions that we should ask ourselves when doing evaluation in complex or diverse populations:</p>
<p style="text-align: left;">1. How does our own privilege filter what we see and understand?
2. How do we come to know what we don’t know – to see what has previously been invisible to us or gone unnoticed?</p>
<p style="text-align: left;">Leslie found question 2 to be particularly thought-provoking.</p>

&nbsp;

&nbsp;

&nbsp;

__Jill:__

Jill was pleased to learn more from evaluator Donna Mertens, who she had previously met at the International Congress of Qualitative Inquiry. From Donna’s Transformative Mixed Methods Evaluation AEA workshop, she took away that:



1. Doing contextually-sensitive mixed methods program evaluation that serves the goals of social justice for the population served AND meets the needs of funders is challenging but not impossible.

2. Bringing all evaluation stakeholders to the table together is a worthwhile aim, but must be done with sensitivity to issues of power, privilege, and history.

If you were unable to go to Minneapolis, we hope that you take away something form our take-aways. More visual take-aways for you to enjoy are viewable on our Picasa page: <a href="https://picasaweb.google.com/116313125623568026879/CRCAEA2012#" rel="noopener noreferrer" target="_blank" title="AEA 2012 album">https://picasaweb.google.com/116313125623568026879/CRCAEA2012\#</a>

Hope to see many of you at next year’s AEA conference in Washingotn, DC!

&nbsp;

<span style="color: #ff9900;">\*Find us on facebook and twitter!</span>
<a href="https://www.facebook.com/CarsonResearchConsultingInc" rel="noopener noreferrer" target="_blank" title="CRC facebook">https://www.facebook.com/CarsonResearchConsultingInc</a>
<a href="https://twitter.com/CarsonResearch" rel="noopener noreferrer" target="_blank" title="CRC Twitter">https://twitter.com/CarsonResearch</a>

